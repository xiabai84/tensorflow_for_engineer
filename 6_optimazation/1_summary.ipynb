{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Optimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## 1. Loss function\n",
    "* MSE\n",
    "* Cross Entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## 2 Activation function\n",
    "\n",
    "    1 Identity\n",
    "    2 Binary Step\n",
    "    3 Sigmoid\n",
    "    4 Tanh\n",
    "    5 ReLU\n",
    "    6 Leaky ReLU\n",
    "    7 Softmax\n",
    "    \n",
    "    \n",
    "Sigmoid functions and their combinations generally work better in the case of classifiers <br>\n",
    "Sigmoids and tanh functions are sometimes avoided due to the vanishing gradient problem <br>\n",
    "ReLU function is a general activation function and is used in most cases these days <br>\n",
    "If we encounter a case of dead neurons in our networks the leaky ReLU function is the best choice <br>\n",
    "Always keep in mind that ReLU function should only be used in the hidden layers <br>\n",
    "As a rule of thumb, you can begin with using ReLU function and then move over to other activation functions in case ReLU doesnâ€™t provide with optimum results <br>\n",
    "\n",
    "https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/ <br>\n",
    "https://www.analyticsvidhya.com/blog/2017/10/fundamentals-deep-learning-activation-functions-when-to-use-them/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## 3 Inititialization\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/initializers <br>\n",
    "https://adventuresinmachinelearning.com/weight-initialization-tutorial-tensorflow/ <br>\n",
    "* random normal\n",
    "* random uniform\n",
    "* truncated normal\n",
    "* xavier\n",
    "* he\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## 4 Use Tensorboard\n",
    "\n",
    "https://www.tensorflow.org/guide/summaries_and_tensorboard <br>\n",
    "Beispiel 5, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## 5 Dropout\n",
    "Coursera Kurs: <br>\n",
    "https://www.coursera.org/lecture/deep-neural-network/understanding-dropout-YaGbR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## 6 Batch normalization\n",
    "\n",
    "https://towardsdatascience.com/batch-normalization-theory-and-how-to-use-it-with-tensorflow-1892ca0173ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "## 7 Hyperparameters\n",
    "Model spezifisch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
