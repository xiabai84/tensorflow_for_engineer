{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Basic API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int64>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(np.arange(10))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The common need of Dataset function for ML\n",
    "* Repeated read of data -> Epoch\n",
    "* Get batch -> define a batchsize for gradient decent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate data from existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.repeat(3).batch(7)\n",
    "\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "    \n",
    "# repeat(3) -> produce 0-9 three times, we will have 30 number \n",
    "# at the end\n",
    "\n",
    "# batch(7) -> means, it will take 7 element each time. After\n",
    "# three iterations (28 items are iterated), we have still 2 \n",
    "# element remain..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Interleave:\n",
    "<br>\n",
    "Iterate over each dataset element and can perform certain operations on the element. After iteration it will collect results together\n",
    "<br>\n",
    "Usecase:\n",
    " <br>\n",
    "It can iterate over a data directory, read all datafiles in that direcotry and collect all peaces of data at the end to one single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# interleave takes three parameters:\n",
    "# 1. map - function -> perform operation / transformation on data\n",
    "# 2. cycle_length -> parallel tasks for the job\n",
    "# 3. block_length -> how many data it should take each time\n",
    "\n",
    "data_merged = dataset.interleave(\n",
    "    lambda x: tf.data.Dataset.from_tensor_slices(x),\n",
    "    cycle_length = 5,\n",
    "    block_length = 5\n",
    ")\n",
    "\n",
    "for item in data_merged:\n",
    "    print(item)\n",
    "    \n",
    "# because block_length is set to 5, it will take 5 element at\n",
    "# once and perform lambda function for it.\n",
    "# for example \n",
    "# from [0 1 2 3 4 5 6] take [0...4], [5, 6] remains\n",
    "# from [7 8 9 0 1 2 3] take [7...1], [2 3] remains\n",
    "# from [4 5 6 7 8 9 0] take [4...8], [9,0] remains\n",
    "# from [1 2 3 4 5 6 7] take [1...5], [6,7] remains\n",
    "# from [8,9] take [8, 9] take [5, 6] from 1. group and 2 from 2.group\n",
    "# [3, 9, 0, 6, 7] ... the rest remaining data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Merge two set together as training and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] b'cat'\n",
      "[3 4] b'dog'\n",
      "[5 6] b'bird'\n"
     ]
    }
   ],
   "source": [
    "train_data = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "label = np.array(['cat', 'dog', 'bird'])\n",
    "\n",
    "zip_data = tf.data.Dataset.from_tensor_slices((train_data, label))\n",
    "\n",
    "for x, y in zip_data:\n",
    "    print(x.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2], shape=(2,), dtype=int64) tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor([3 4], shape=(2,), dtype=int64) tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor([5 6], shape=(2,), dtype=int64) tf.Tensor(b'bird', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# zip as dict\n",
    "train_data = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "label = np.array(['cat', 'dog', 'bird'])\n",
    "\n",
    "zip_data = tf.data.Dataset.from_tensor_slices(\n",
    "                                {\n",
    "                                    \"feature\": train_data,\n",
    "                                    \"label\": label\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "for item in zip_data:\n",
    "    print(item[x], item[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
