{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassisches Problem mit NN\n",
    "* zu viele Gewichte (Weights) -> hohe Rechenkapazität\n",
    "* wegen sehr vieler Gewichte wird mehr Sample Data gebraucht\n",
    "<br>\n",
    "Erfahrungsgemäß sollte die Anzahl der gesamten Trainingsdatasets 5-30 mals mehr als die Anzhal der Parameters (Weights) sein"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Convolution\n",
    "![title](image/Convolution_Operation.png)\n",
    "<br>\n",
    "* Lineare Operation, die zwei Signale zusammenführt\n",
    "* Convolution = Falten\n",
    "\n",
    "* Vorgehen:\n",
    "* Kernel fährt über das Bild\n",
    "* Kernel \"sucht\" nach Muster\n",
    "* Mehrere Kernels in einem Convolution Layer (CNN sucht nach mehreren Featuers im Bild)\n",
    "*\n",
    "* Vorteile gegenüber andern NNs:\n",
    "* Keine Konvertierung des Inputs zu eindimensionalem Vektor\n",
    "* Räumliche Information bleibt erhalten\n",
    "* Weniger Paramter benötigt\n",
    "* Model unabhängig von Dimension des Inputs\n",
    "\n",
    "\n",
    "## 2. 1 Architektur der CNN\n",
    "![title](image/1_architecture_cnn.png)\n",
    "## 2.2 Beispiel\n",
    "<br>\n",
    "\n",
    "**Input -> Filter -> FeatureMap**\n",
    "\n",
    "![title](image/2_filter_cnn.png)\n",
    "\n",
    "## 2.3 CNN Komponenten\n",
    "### 2.3.1 Convolutional Layer\n",
    "* input data shape -> [5, 5, 3]\n",
    "* output/num of filters -> (2)\n",
    "* filter_size -> (3 x 3)\n",
    "* padding -> (**same**|valid)\n",
    "* strides -> (2, 2)\n",
    "\n",
    "![title](image/3_conv_filter.jpg)\n",
    "\n",
    "### 2.3.2 Pooling Layer\n",
    "\n",
    "* input(convolutional layer) -> [224, 224, 64]\n",
    "* pooling -> (**max**|average) \n",
    "* kernel_size -> (2, 2)\n",
    "* strides -> (2, 2)\n",
    "* output -> (64)\n",
    "\n",
    "![title](image/4_max_pooling.png)\n",
    "\n",
    "### 2.3.3 Fully connected layer\n",
    "\n",
    "* flatten all feature maps (matrix) in one row vector\n",
    "* activation function -> relu\n",
    "* output (output neurons)\n",
    "* from output -> n neurons == n classifications\n",
    "\n",
    "![title](image/5_fully_connected_layer.png)\n",
    "\n",
    "## 2.4 Hyperparameters\n",
    "\n",
    "* Kernel size (K) - Größe des Fensters in Pixeln (Bsp. 1-5)\n",
    "* Stride (S) - Anzahl Pixel, um die das Fenster pro Schritt weiter geschoben wird (Bsp. 1)\n",
    "* Zero padding (pad) - Nullen um den Fensterrand (So dass auch Bildränder gefiltert werden können)\n",
    "* Anzahl der Filter - Die Anzahl der Filter in unserem Conolution Layer entscheidet über die Anzahl der Features, die unser Modell lernen kann.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
